# Infant-wearable-project
We aim to build an opne-source infant wearable platform to collect and analyze long-form audio, video, and position data from infants in naturalistic home settings. This project focuses on building and benchmarking the data analysis pipeline that enables automated recognition of infant-directed speech (IDS), caregiver behaviors, and object references to support scalable developmental research.

Current efforts include:
	•	Speech Analysis: Transcribing infant-directed speech using Whisper 
	•	Multilingual Benchmarking: Benchmarking ASR performance on Mandarin and English datasets 
	•	Visual Object Identification: Detecting and labeling referential objects from video data to link language input to visual context

Our goal is to create reproducible, low-cost tools for developmental researchers worldwide and contribute to a more inclusive, scalable model of early childhood data collection and analysis.

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4e852b-1a53-43c1-b1af-b8a0e828c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc4508-c69d-4bfa-9557-76082b16c03b",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "# Parent-Infant Interaction Audio Analysis System\n",
    "\n",
    "## Overview\n",
    "This system consists of two main components:\n",
    "1. Audio Transcription Pipeline using Whisper ASR\n",
    "2. Transcription Comparison and Validation Tool\n",
    "\n",
    "## Component 1: Audio Transcription\n",
    "### Features\n",
    "- Uses OpenAI's Whisper ASR model (large-v2)\n",
    "- Specialized for parent-infant interactions\n",
    "- Includes speaker detection capabilities\n",
    "- Handles both verbal and non-verbal vocalizations\n",
    "\n",
    "### Key Functions\n",
    "1. `transcribe_audio(audio_path, speaker_hints)`\n",
    "   - Input: Audio file path\n",
    "   - Output: DataFrame with transcribed segments\n",
    "   - Features:\n",
    "     * Word-level timestamps\n",
    "     * Duration tracking\n",
    "     * Optional speaker detection\n",
    "     * Parent-infant interaction specific prompting\n",
    "\n",
    "2. `detect_speaker(text, speaker_hints)`\n",
    "   - Categorizes speech segments into:\n",
    "     * [Baby Crying]\n",
    "     * [Baby Laughing]\n",
    "     * [Infant Vocalization]\n",
    "     * [Mother]\n",
    "     * [Father]\n",
    "     * [Unspecified]\n",
    "\n",
    "## Component 2: Transcription Comparison\n",
    "### Features\n",
    "- Compares Whisper ASR output with human transcriptions\n",
    "- Provides multiple accuracy metrics\n",
    "- Generates detailed segment-by-segment analysis\n",
    "- Exports comparison results in spreadsheet format\n",
    "\n",
    "### Key Metrics\n",
    "1. Text Similarity\n",
    "   - SequenceMatcher score (Ratcliff/Obershelp algorithm)\n",
    "   - Formula: ratio = 2.0 * M / T\n",
    "     * M = sum of lengths of matched subsequences\n",
    "     * T = total length of both strings combined\n",
    "\n",
    "2. Word-level Analysis\n",
    "   - Word count comparison\n",
    "   - Correct words identification\n",
    "   - Mismatch detection\n",
    "   - Accuracy percentage calculation\n",
    "\n",
    "### Output Format\n",
    "CSV file with columns:\n",
    "- Time Range\n",
    "- Whisper Transcription\n",
    "- Human Transcription\n",
    "- SequenceMatcher Score\n",
    "- Word Count (Human)\n",
    "- Word Count (Whisper)\n",
    "- Correct Words\n",
    "- Mismatches\n",
    "- Accuracy (%)\n",
    "- Comments/Notes\n",
    "\n",
    "## Usage Workflow\n",
    "1. Transcribe Audio:\n",
    "```python\n",
    "df, result = transcribe_audio(\n",
    "    \"path/to/audio.wav\",\n",
    "    speaker_hints=[\"[Mother]\", \"[Father]\", \"[Baby]\", ...]\n",
    ")\n",
    "```\n",
    "\n",
    "2. Compare with Human Transcription:\n",
    "```python\n",
    "results_df, stats = compare_and_export(\n",
    "    whisper_df,\n",
    "    human_df,\n",
    "    \"comparison_results.csv\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Technical Notes\n",
    "- Time tolerance: 0.5 seconds for segment matching\n",
    "- Similarity threshold: 0.3 for considering matches\n",
    "- Text cleaning includes:\n",
    "  * Case normalization\n",
    "  * Punctuation removal\n",
    "  * Common transcription variant standardization\n",
    "- High quality matches: Accuracy > 80%\n",
    "- Low quality matches: Accuracy < 60%\n",
    "\n",
    "## File Paths\n",
    "- Audio Input: '/path/to/media/12mon/IW_ID_MONTH_TL.wav'\n",
    "- Whisper Output: '/path/to/transcription/12mon/ID_MONTH_whisper_results_without_speaker.csv'\n",
    "- Comparison Output: '/path/to/transcription/12mon/ID_MONTH_transcription_comparison.csv'\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f4367a-1c2c-4daf-b51a-98e1790e6607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/yueyan/.pyenv/versions/3.9.7/lib/python3.9/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3a864b-ea69-403a-b401-2fb875d8cb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yueyan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yueyan/.pyenv/versions/3.9.7/lib/python3.9/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:27.180 --> 01:29.980]  Please transcribe all speech, including infant vocalizations, parent speech, and any notable sounds.\n",
      "[01:53.640 --> 01:57.700]  Please transcribe all speech, including infant vocalizations, parent speech, and any notable sounds.\n",
      "[02:05.740 --> 02:13.280]  Please transcribe all speech, including infant vocalizations, parent speech, and any notable sounds.\n",
      "[02:30.560 --> 02:32.580]  What do you have, a ring?\n",
      "[02:34.060 --> 02:35.080]  Squeak!\n",
      "[02:38.000 --> 02:38.520]  Squeak!\n",
      "[02:40.200 --> 02:42.220]  Uh-uh, a ring?\n",
      "[02:44.060 --> 02:44.840]  Yeah.\n",
      "[02:45.880 --> 02:46.460]  Ah!\n",
      "[02:51.000 --> 02:51.100]  Ah!\n",
      "[02:52.300 --> 02:53.720]  Yeah, it's a ring.\n",
      "[02:54.660 --> 02:55.980]  Thank you.\n",
      "[02:58.000 --> 02:58.620]  Thank you.\n",
      "[03:00.520 --> 03:01.860]  Can I have that?\n",
      "[03:02.280 --> 03:02.940]  Thank you.\n",
      "[03:03.200 --> 03:04.180]  You want it back?\n",
      "[03:04.740 --> 03:05.540]  It squeaks.\n",
      "[03:07.040 --> 03:08.300]  You want the ring?\n",
      "[03:09.680 --> 03:10.760]  Thank you.\n",
      "[03:11.920 --> 03:12.940]  Thank you.\n",
      "[03:18.140 --> 03:19.600]  Thank you very much.\n",
      "[03:22.980 --> 03:24.160]  You want a pickle?\n",
      "[03:30.580 --> 03:31.420]  Lion.\n",
      "[03:36.020 --> 03:37.180]  Thank you.\n",
      "[03:37.960 --> 03:39.940]  Where's the other one? You see another ring?\n",
      "[03:46.060 --> 03:47.200]  Thank you.\n",
      "[03:48.540 --> 03:49.640]  Thank you.\n",
      "[03:57.800 --> 03:59.360]  A green one!\n",
      "[04:00.000 --> 04:00.420]  Squeak!\n",
      "[04:04.260 --> 04:04.880]  Squeak!\n",
      "[04:05.340 --> 04:05.620]  Squeak!\n",
      "[04:06.540 --> 04:08.240]  Where are you going? Come here!\n",
      "[04:08.560 --> 04:11.060]  Hi, Buzz!\n",
      "[04:14.000 --> 04:14.040]  Ah!\n",
      "[04:15.240 --> 04:17.520]  Come over here! No, not yet!\n",
      "[04:19.000 --> 04:19.660]  Come over here!\n",
      "[04:20.620 --> 04:23.720]  No, not yet! You can see those hands in it.\n",
      "[04:25.520 --> 04:26.920]  Oh, come here!\n",
      "[04:26.920 --> 04:27.040]  Come here!\n",
      "[04:27.980 --> 04:28.780]  Come here, Buzz!\n",
      "[04:29.240 --> 04:29.940]  Come here!\n",
      "[04:32.920 --> 04:33.140]  Yeah!\n",
      "[04:35.480 --> 04:36.500]  Thank you.\n",
      "[04:37.020 --> 04:38.660]  No? A green one?\n",
      "[04:40.480 --> 04:41.960]  Look at the ladybug!\n",
      "[04:42.700 --> 04:43.120]  Whoa!\n",
      "[04:44.940 --> 04:46.400]  Is it red and green?\n",
      "[04:46.800 --> 04:46.800]  Watch!\n",
      "[04:50.400 --> 04:51.140]  Can I get him?\n",
      "[04:52.920 --> 04:53.540]  Good girl!\n",
      "[04:56.940 --> 04:57.380]  Ah!\n",
      "[05:03.040 --> 05:03.980]  Bubby, where are you going?\n",
      "[05:05.080 --> 05:06.240]  Look at the red and green!\n",
      "[05:07.080 --> 05:07.520]  Look!\n",
      "[05:08.480 --> 05:08.920]  Check!\n",
      "[05:10.100 --> 05:10.540]  Check!\n",
      "[05:11.120 --> 05:12.820]  Ooh! Come here!\n",
      "[05:14.060 --> 05:14.740]  Come here!\n",
      "[05:15.600 --> 05:16.260]  Hi, Buzz!\n",
      "[05:17.500 --> 05:19.480]  No, honey, you can have that later. Come here!\n",
      "[05:20.580 --> 05:22.500]  You can have that one later, honey.\n",
      "[05:22.800 --> 05:24.100]  I know you want to see that one.\n",
      "[05:25.920 --> 05:27.220]  Come here, Bubby!\n",
      "[05:28.100 --> 05:29.760]  You can have that later.\n",
      "[05:32.060 --> 05:33.240]  Come here! Look!\n",
      "[05:35.940 --> 05:36.020]  Ah!\n",
      "[05:37.880 --> 05:38.260]  See?\n",
      "[05:41.560 --> 05:43.780]  Come here, Bubby! You can do that later.\n",
      "[05:47.920 --> 05:48.640]  Hi!\n",
      "[05:49.580 --> 05:50.300]  Hi!\n",
      "[05:52.500 --> 05:53.220]  Watch!\n",
      "[05:53.220 --> 05:53.800]  Watch!\n",
      "[05:55.560 --> 05:56.640]  You can let it breathe.\n",
      "[05:57.400 --> 05:57.800]  Air.\n",
      "[06:00.220 --> 06:01.020]  Oh, bubby!\n",
      "[06:05.780 --> 06:08.220]  You want to go ahead and switch some because the morning...\n",
      "[06:08.220 --> 06:09.640]  Oh, that's right. I can do that.\n",
      "[06:09.780 --> 06:10.360]  That's fine.\n",
      "[06:10.380 --> 06:11.580]  Yeah, I can combo.\n",
      "[06:12.400 --> 06:14.520]  And then if you want to go ahead and put those in...\n",
      "[06:14.520 --> 06:14.720]  Yeah.\n",
      "[06:15.660 --> 06:15.980]  Great.\n",
      "[06:15.980 --> 06:16.020]  Okay.\n",
      "[06:22.340 --> 06:22.820]  Oops!\n",
      "[06:24.680 --> 06:25.620]  Look, Bubby!\n",
      "[06:27.060 --> 06:27.960]  Look at this!\n",
      "[06:31.520 --> 06:33.840]  Yeah, there you go. That's what you want to see.\n",
      "[06:49.540 --> 06:50.920]  Watch, watch.\n",
      "[06:51.100 --> 06:52.140]  Do that there.\n",
      "[07:06.300 --> 07:08.500]  There you go.\n",
      "[07:16.980 --> 07:17.020]  Okay!\n",
      "[07:17.880 --> 07:19.660]  That's all you need.\n",
      "[07:19.860 --> 07:21.260]  Restart.\n",
      "[07:23.400 --> 07:24.800]  Make sure that it has been filmed okay.\n",
      "[07:26.000 --> 07:27.400]  That's what you think, right?\n",
      "[07:27.400 --> 07:34.860]  Can we explain to them what exactly workforce means?\n",
      "[07:34.860 --> 07:44.480]  Yes, it is!\n",
      "[07:44.480 --> 07:44.480]  Exactly!\n",
      "[07:45.880 --> 07:46.660]  There we go.\n",
      "[07:53.480 --> 07:53.960]  Like that.\n",
      "[07:53.960 --> 07:55.060]  Put your hand out in the middle.\n",
      "[07:57.960 --> 07:58.920]  I'm sorry.\n",
      "[08:19.080 --> 08:22.640]  I think that's the big one.\n",
      "[08:22.640 --> 08:23.460]  There's another one right there.\n",
      "[08:31.880 --> 08:33.520]  I think that's the big one.\n",
      "[08:34.020 --> 08:34.900]  There's another one.\n",
      "[08:37.180 --> 08:38.760]  I think that's the big one.\n",
      "[09:05.440 --> 09:07.400]  I think that's the big one.\n",
      "[09:18.800 --> 09:19.880]  Hey buddy.\n",
      "[09:21.300 --> 09:22.880]  You're going to give mommy one?\n",
      "[09:23.280 --> 09:24.300]  Can I have one?\n",
      "[09:36.000 --> 09:37.480]  Can I have one, buddy?\n",
      "[09:38.320 --> 09:40.720]  Can I have mommy one? Thank you.\n",
      "[09:40.940 --> 09:41.720]  How can I help you?\n",
      "[09:42.300 --> 09:43.240]  You want to eat it?\n",
      "[10:04.900 --> 10:05.680]  Is that orange?\n",
      "[10:10.220 --> 10:11.220]  Look puppy.\n",
      "[10:12.120 --> 10:12.720]  There you go.\n",
      "[10:12.880 --> 10:13.800]  Where's the orange one?\n",
      "[10:14.600 --> 10:15.760]  There it is.\n",
      "[10:18.440 --> 10:19.480]  Where'd it go?\n",
      "[10:20.780 --> 10:21.940]  There it is.\n",
      "[10:22.320 --> 10:23.040]  Did you find it?\n",
      "[10:23.200 --> 10:24.040]  Good job.\n",
      "[10:35.900 --> 10:36.040]  Okay.\n",
      "[10:40.180 --> 10:42.040]  There's the orange one.\n",
      "[10:51.900 --> 10:53.420]  There's a box here.\n",
      "[11:01.320 --> 11:02.400]  There's the orange one.\n",
      "[11:02.480 --> 11:04.000]  Good job.\n",
      "[11:05.160 --> 11:06.280]  Let mommy go get it.\n",
      "[11:09.560 --> 11:10.520]  There you go.\n",
      "[11:15.160 --> 11:16.300]  Let mommy see.\n",
      "[11:16.800 --> 11:17.840]  Put it in here.\n",
      "[11:17.980 --> 11:18.840]  Put the ball in here.\n",
      "[11:18.840 --> 11:18.960]  Come here.\n",
      "[11:21.320 --> 11:22.560]  Put the ball in here, puppy.\n",
      "[11:25.140 --> 11:25.540]  Puppy.\n",
      "[11:27.280 --> 11:28.860]  Hey puppy, put the ball in here.\n",
      "[11:30.520 --> 11:31.860]  Jack, put the ball in here.\n",
      "[11:34.120 --> 11:34.920]  Good job.\n",
      "[11:36.120 --> 11:37.100]  Does it fit in there?\n",
      "[11:38.320 --> 11:40.600]  Do you want to put it to the last one?\n",
      "[11:41.000 --> 11:41.200]  Okay.\n",
      "[11:42.260 --> 11:43.660]  Jack, we're going to put these back.\n",
      "[11:43.660 --> 11:43.920]  Put it back.\n",
      "[11:48.660 --> 11:49.400]  You did better.\n",
      "[11:49.960 --> 11:51.780]  I like those.\n",
      "[12:05.320 --> 12:07.020]  There's a boat.\n",
      "[12:08.640 --> 12:09.780]  A boat.\n",
      "[12:13.660 --> 12:14.380]  A parrot.\n",
      "[12:20.660 --> 12:22.040]  A turtle.\n",
      "[12:23.760 --> 12:25.060]  Is that for me, though?\n",
      "[12:26.400 --> 12:27.500]  What's his name?\n",
      "[12:30.480 --> 12:32.460]  A squirt or something.\n",
      "[12:33.700 --> 12:34.740]  A pirate.\n",
      "[12:40.960 --> 12:42.160]  Come here.\n",
      "[12:42.320 --> 12:42.500]  Come here, puppy.\n",
      "[12:43.160 --> 12:44.040]  Look at the boat.\n",
      "[12:46.640 --> 12:47.920]  Come here, puppies.\n",
      "[12:50.500 --> 12:51.620]  There you go. Look.\n",
      "[12:52.260 --> 12:54.700]  Jack, the pirate's in there.\n",
      "[12:58.860 --> 13:00.660]  The pirate. Get back over here.\n",
      "[13:01.100 --> 13:02.160]  I like that.\n",
      "[13:03.380 --> 13:05.680]  I like the fireplace, good girl.\n",
      "[13:05.960 --> 13:06.880]  I like the fireplace.\n",
      "[13:12.740 --> 13:15.100]  You can put the pirate in here.\n",
      "[13:16.880 --> 13:19.300]  You like this, girl?\n",
      "[13:33.800 --> 13:34.960]  I got a pirate.\n",
      "[13:35.240 --> 13:35.700]  A parrot.\n",
      "[13:36.680 --> 13:37.700]  Put him in here.\n",
      "[13:38.540 --> 13:39.540]  Put it in there.\n",
      "[13:42.180 --> 13:43.740]  The turtle. Look at the turtle.\n",
      "[13:44.560 --> 13:45.420]  You want to put him in here?\n",
      "[13:54.400 --> 13:55.960]  You want to put the turtle in there?\n",
      "[13:57.380 --> 13:58.240]  There you go.\n",
      "[13:58.800 --> 14:00.000]  How about pirate again?\n",
      "[14:00.000 --> 14:01.220]  You want to go over there?\n",
      "[14:02.940 --> 14:04.960]  Good job. Are you cleaning up?\n",
      "[14:05.580 --> 14:06.580]  You want to put the pirate in there?\n",
      "[14:10.000 --> 14:11.500]  You want to put that in here?\n",
      "[14:12.880 --> 14:14.060]  You want to put that in there?\n",
      "[14:16.960 --> 14:18.380]  You want to put that in there?\n",
      "[14:20.300 --> 14:22.480]  Ah, there you go.\n",
      "[14:23.780 --> 14:24.720]  There you go.\n",
      "[14:34.440 --> 14:35.700]  Are you going to eat the ball?\n",
      "[14:36.040 --> 14:36.240]  Okay.\n",
      "[14:37.000 --> 14:37.960]  You want to put that in there?\n",
      "[14:43.220 --> 14:44.520]  Ah, that doesn't roll.\n",
      "[14:44.700 --> 14:45.520]  Hold on, there it does.\n",
      "[14:49.920 --> 14:51.320]  You want to put it on his head?\n",
      "[14:51.600 --> 14:52.300]  On his hat?\n",
      "[14:54.320 --> 14:55.500]  Okay, good job.\n",
      "[14:55.600 --> 14:56.360]  You want to go get it?\n",
      "[14:57.380 --> 14:58.200]  Go get it.\n",
      "[15:00.380 --> 15:01.900]  You want to bring it back to mom?\n",
      "[15:03.180 --> 15:04.460]  Jack, bring it back to mom.\n",
      "[15:07.640 --> 15:09.180]  Come back to mom.\n",
      "[15:09.780 --> 15:10.380]  Come here.\n",
      "[15:11.220 --> 15:11.740]  Jack.\n",
      "[15:13.100 --> 15:13.900]  Jack, Jack.\n",
      "[15:15.680 --> 15:16.200]  Bubby.\n",
      "[15:18.460 --> 15:19.420]  Come here.\n",
      "[15:20.600 --> 15:21.340]  Are you playing?\n",
      "[15:22.260 --> 15:24.020]  Bring the ball back to mom.\n",
      "[15:24.700 --> 15:25.780]  Can you get the ball, Jack?\n",
      "[15:26.700 --> 15:27.960]  Where did it go?\n",
      "[15:27.960 --> 15:29.360]  Go get the ball.\n",
      "[15:30.380 --> 15:32.140]  Go get that ball, Jack.\n",
      "[15:33.000 --> 15:33.700]  Go get the ball.\n",
      "[15:33.720 --> 15:34.720]  Is that the yellow ball?\n",
      "[15:37.920 --> 15:40.020]  Is this where you play, mommy?\n",
      "[15:40.520 --> 15:42.260]  This is where you play.\n",
      "[15:42.260 --> 15:43.220]  Okay, wait.\n",
      "[15:44.420 --> 15:45.640]  Go look at the crew.\n",
      "[15:48.480 --> 15:49.540]  It's time to go.\n",
      "[15:50.060 --> 15:50.360]  Okay, alright.\n",
      "[15:52.880 --> 15:54.500]  You want to put the ball in here, Jack?\n",
      "[15:54.800 --> 15:55.660]  I love these.\n",
      "[15:56.140 --> 15:56.840]  Oh, yeah?\n",
      "[15:57.040 --> 15:57.840]  It's good.\n",
      "[16:00.800 --> 16:01.900]  How was that?\n",
      "[16:04.020 --> 16:05.420]  Can you guys see these?\n",
      "[16:11.680 --> 16:15.180]  It's hard to get him not to go over and get all the other stuff.\n",
      "[16:15.420 --> 16:15.660]  Really?\n",
      "[16:15.940 --> 16:18.560]  We're going to have to figure out a better way to do that.\n",
      "[16:19.420 --> 16:21.560]  The second batch was his favorite.\n",
      "[16:26.240 --> 16:27.660]  He likes stepping and...\n",
      "[16:28.820 --> 16:29.520]  I don't know what it was.\n",
      "[16:30.060 --> 16:30.900]  The ball.\n",
      "[16:33.460 --> 16:34.400]  Throw the ball.\n",
      "[16:36.100 --> 16:37.300]  You want to throw it?\n",
      "[16:38.760 --> 16:39.460]  It's funny.\n",
      "[16:39.620 --> 16:41.600]  He didn't throw for a while.\n",
      "[16:41.740 --> 16:43.300]  He was just putting everything in his mouth.\n",
      "[16:43.440 --> 16:44.940]  He doesn't do that anymore.\n",
      "[16:45.080 --> 16:47.040]  He's really, really, really...\n",
      "[16:47.040 --> 16:50.480]  Well, I say a couple things.\n",
      "[16:51.360 --> 16:53.540]  Not automatically, you know, right in the mouth.\n",
      "[16:55.660 --> 16:56.660]  Oh, no.\n",
      "[16:57.220 --> 16:58.040]  What?\n",
      "[17:04.980 --> 17:07.960]  Where's the ducky?\n",
      "[17:09.660 --> 17:09.720]  Jack.\n",
      "[17:11.180 --> 17:11.980]  Where's the ducky?\n",
      "\n",
      "Transcription Statistics:\n",
      "Total segments: 241\n",
      "\n",
      "Speaker distribution:\n",
      "speaker\n",
      "[Unspecified]            224\n",
      "[Mother]                   9\n",
      "[Infant Vocalization]      8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few transcriptions:\n",
      "  start_time end_time                                               text\n",
      "0    0:01:27  0:01:29  Please transcribe all speech, including infant...\n",
      "1    0:01:53  0:01:57  Please transcribe all speech, including infant...\n",
      "2    0:02:05  0:02:13  Please transcribe all speech, including infant...\n",
      "3    0:02:30  0:02:32                          What do you have, a ring?\n",
      "4    0:02:34  0:02:35                                            Squeak!\n",
      "\n",
      "First few transcriptions with speakers:\n",
      "  start_time end_time        speaker  \\\n",
      "0    0:01:27  0:01:29  [Unspecified]   \n",
      "1    0:01:53  0:01:57  [Unspecified]   \n",
      "2    0:02:05  0:02:13  [Unspecified]   \n",
      "3    0:02:30  0:02:32  [Unspecified]   \n",
      "4    0:02:34  0:02:35  [Unspecified]   \n",
      "\n",
      "                                                text  \n",
      "0  Please transcribe all speech, including infant...  \n",
      "1  Please transcribe all speech, including infant...  \n",
      "2  Please transcribe all speech, including infant...  \n",
      "3                          What do you have, a ring?  \n",
      "4                                            Squeak!  \n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "def transcribe_audio(audio_path, speaker_hints=None):\n",
    "    \"\"\"Transcribe audio using Whisper with enhanced speaker detection\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    model = whisper.load_model(\"large-v2\", device=\"cpu\")\n",
    "    \n",
    "    # Keep the parent-infant context in the prompt but make it more transcription-focused\n",
    "    initial_prompt = \"\"\"This is a parent-infant interaction recording. \n",
    "    Please transcribe all speech, including infant vocalizations, parent speech, and any notable sounds.\n",
    "    Include both verbal and non-verbal vocalizations.\"\"\"\n",
    "    \n",
    "    print(\"Transcribing...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        word_timestamps=True,\n",
    "        verbose=True,\n",
    "        initial_prompt=initial_prompt,\n",
    "        language=\"en\",\n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    # Process segments\n",
    "    segments = []\n",
    "    \n",
    "    # First pass: Get clean transcriptions with timing\n",
    "    for segment in result[\"segments\"]:\n",
    "        text = segment[\"text\"].strip()\n",
    "        start = segment[\"start\"]\n",
    "        end = segment[\"end\"]\n",
    "        duration = end - start\n",
    "        \n",
    "        # Skip empty segments\n",
    "        if not text:\n",
    "            continue\n",
    "            \n",
    "        segment_info = {\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'start_time': str(timedelta(seconds=int(start))),\n",
    "            'end_time': str(timedelta(seconds=int(end))),\n",
    "            'text': text,\n",
    "            'duration': duration\n",
    "        }\n",
    "        \n",
    "        # Optional: Add speaker detection without modifying the original text\n",
    "        if speaker_hints:\n",
    "            speaker = detect_speaker(text, speaker_hints)\n",
    "            segment_info['speaker'] = speaker\n",
    "        \n",
    "        segments.append(segment_info)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(segments)\n",
    "    \n",
    "    return df, result\n",
    "\n",
    "def detect_speaker(text, speaker_hints):\n",
    "    \"\"\"Separate function for speaker detection that doesn't modify the transcription\"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Basic speaker detection logic\n",
    "    if any(word in text_lower for word in ['crying', 'cries', 'waa']):\n",
    "        return '[Baby Crying]'\n",
    "    elif any(word in text_lower for word in ['laugh', 'giggle']):\n",
    "        return '[Baby Laughing]'\n",
    "    elif any(word in text_lower for word in ['goo', 'gah', 'bah', 'coo']):\n",
    "        return '[Infant Vocalization]'\n",
    "    elif '[mother]' in text_lower or 'mom' in text_lower:\n",
    "        return '[Mother]'\n",
    "    elif '[father]' in text_lower or 'dad' in text_lower:\n",
    "        return '[Father]'\n",
    "    else:\n",
    "        return '[Unspecified]'\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    speaker_hints = [\n",
    "        \"[Mother]\", \"[Father]\", \"[Baby]\",\n",
    "        \"[Infant Vocalization]\", \"[Baby Crying]\", \"[Baby Laughing]\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        df, result = transcribe_audio(\n",
    "            \"/Users/yueyan/Documents/project/wearable/media/12mon/IW_002_12_TL.wav\",\n",
    "            speaker_hints=speaker_hints\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        df.to_csv(\"/Users/yueyan/Documents/project/wearable/transcription/12mon/002_12_whisper_results_without_speaker.csv\", index=False)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nTranscription Statistics:\")\n",
    "        print(f\"Total segments: {len(df)}\")\n",
    "        \n",
    "        # If speaker detection is enabled\n",
    "        if 'speaker' in df.columns:\n",
    "            print(\"\\nSpeaker distribution:\")\n",
    "            print(df['speaker'].value_counts())\n",
    "        \n",
    "        print(\"\\nFirst few transcriptions:\")\n",
    "        print(df[['start_time', 'end_time', 'text']].head())\n",
    "        \n",
    "        # Optionally display with speakers if available\n",
    "        if 'speaker' in df.columns:\n",
    "            print(\"\\nFirst few transcriptions with speakers:\")\n",
    "            print(df[['start_time', 'end_time', 'speaker', 'text']].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0be6b912-4d90-4314-b6c1-cfe298211fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing segments: 118it [00:00, 2660.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Summary:\n",
      "Total segments analyzed: 95\n",
      "Average accuracy: 65.3%\n",
      "Average similarity score: 0.756\n",
      "High quality matches (>80%): 39\n",
      "Low quality matches (<60%): 38\n",
      "\n",
      "Sample comparison results:\n",
      "    Time Range Human Transcription Whisper Transcription  Accuracy (%)\n",
      "0  157.7-158.4             squeak.               Squeak!         100.0\n",
      "1  164.1-165.3               yeah.                 Yeah.         100.0\n",
      "2  172.5-174.0  yeah it's a rings.    Yeah, it's a ring.          75.0\n",
      "3  177.9-178.8          thank you.            Thank you.         100.0\n",
      "4  182.3-183.0          thank you.            Thank you.         100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "class EnhancedTranscriptionComparator:\n",
    "    def __init__(self, whisper_df: pd.DataFrame, human_df: pd.DataFrame):\n",
    "        \"\"\"Initialize with enhanced text cleaning and comparison capabilities\"\"\"\n",
    "        self.whisper_data = whisper_df.copy()\n",
    "        self.human_data = human_df.copy()\n",
    "        \n",
    "        # Pre-clean the data\n",
    "        self.human_data = self.human_data[self.human_data['text'].notna()]\n",
    "        if 'end ' in self.human_data.columns:\n",
    "            self.human_data = self.human_data.rename(columns={'end ': 'end'})\n",
    "        \n",
    "        # Convert times to numeric\n",
    "        self.human_data['start'] = pd.to_numeric(self.human_data['start'])\n",
    "        self.human_data['end'] = pd.to_numeric(self.human_data['end'])\n",
    "        \n",
    "        # Clean text and store originals\n",
    "        self.whisper_data['clean_text'] = self.whisper_data['text'].apply(self.clean_text)\n",
    "        self.human_data['clean_text'] = self.human_data['text'].apply(self.clean_text)\n",
    "        self.whisper_data['original_text'] = self.whisper_data['text']\n",
    "        self.human_data['original_text'] = self.human_data['text']\n",
    "        \n",
    "        # Find overlap range\n",
    "        self.overlap_start = max(self.whisper_data['start'].min(), self.human_data['start'].min())\n",
    "        self.overlap_end = min(self.whisper_data['end'].max(), self.human_data['end'].max())\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Enhanced text cleaning function\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "            \n",
    "        text = str(text).lower()\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        replacements = {\n",
    "            'uhm': 'um', 'uhh': 'uh', 'hmm': 'hm',\n",
    "            'mhm': 'mm', 'yeah': 'yes', 'yah': 'yes',\n",
    "            'nah': 'no'\n",
    "        }\n",
    "        \n",
    "        for old, new in replacements.items():\n",
    "            text = re.sub(r'\\b' + old + r'\\b', new, text)\n",
    "            \n",
    "        return text\n",
    "\n",
    "    def get_word_metrics(self, human_text: str, whisper_text: str) -> Dict[str, int]:\n",
    "        \"\"\"Calculate detailed word-level metrics\"\"\"\n",
    "        human_words = set(self.clean_text(human_text).split())\n",
    "        whisper_words = set(self.clean_text(whisper_text).split())\n",
    "        \n",
    "        correct_words = len(human_words.intersection(whisper_words))\n",
    "        total_words_human = len(human_words)\n",
    "        total_words_whisper = len(whisper_words)\n",
    "        mismatches = max(total_words_human, total_words_whisper) - correct_words\n",
    "        \n",
    "        return {\n",
    "            'word_count_human': total_words_human,\n",
    "            'word_count_whisper': total_words_whisper,\n",
    "            'correct_words': correct_words,\n",
    "            'mismatches': mismatches\n",
    "        }\n",
    "\n",
    "    def generate_comparison_results(self, time_tolerance: float = 0.5, \n",
    "                                  similarity_threshold: float = 0.3) -> pd.DataFrame:\n",
    "        \"\"\"Generate comprehensive comparison results for spreadsheet\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        human_segments = self.human_data[\n",
    "            (self.human_data['start'] >= self.overlap_start) &\n",
    "            (self.human_data['end'] <= self.overlap_end)\n",
    "        ]\n",
    "        \n",
    "        whisper_segments = self.whisper_data[\n",
    "            (self.whisper_data['start'] >= self.overlap_start) &\n",
    "            (self.whisper_data['end'] <= self.overlap_end)\n",
    "        ]\n",
    "        \n",
    "        for _, human_seg in tqdm(human_segments.iterrows(), desc=\"Analyzing segments\"):\n",
    "            potential_matches = whisper_segments[\n",
    "                (whisper_segments['start'] >= human_seg['start'] - time_tolerance) &\n",
    "                (whisper_segments['start'] <= human_seg['end'] + time_tolerance)\n",
    "            ]\n",
    "            \n",
    "            for _, whisper_seg in potential_matches.iterrows():\n",
    "                similarity = SequenceMatcher(\n",
    "                    None,\n",
    "                    human_seg['clean_text'],\n",
    "                    whisper_seg['clean_text']\n",
    "                ).ratio()\n",
    "                \n",
    "                if similarity > similarity_threshold:\n",
    "                    # Get word-level metrics\n",
    "                    word_metrics = self.get_word_metrics(\n",
    "                        human_seg['original_text'],\n",
    "                        whisper_seg['original_text']\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    accuracy = (word_metrics['correct_words'] / word_metrics['word_count_human'] * 100) \\\n",
    "                        if word_metrics['word_count_human'] > 0 else 0\n",
    "                    \n",
    "                    # Generate comments\n",
    "                    comments = []\n",
    "                    if similarity < 0.5:\n",
    "                        comments.append(\"Low similarity score\")\n",
    "                    if abs(word_metrics['word_count_human'] - word_metrics['word_count_whisper']) > 3:\n",
    "                        comments.append(\"Significant word count difference\")\n",
    "                    if accuracy < 60:\n",
    "                        comments.append(\"Low accuracy\")\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Time Range': f\"{human_seg['start']:.1f}-{human_seg['end']:.1f}\",\n",
    "                        'Whisper Transcription': whisper_seg['original_text'],\n",
    "                        'Human Transcription': human_seg['original_text'],\n",
    "                        'SequenceMatcher Score': round(similarity, 3),\n",
    "                        'Word Count (Human)': word_metrics['word_count_human'],\n",
    "                        'Word Count (Whisper)': word_metrics['word_count_whisper'],\n",
    "                        'Correct Words': word_metrics['correct_words'],\n",
    "                        'Mismatches': word_metrics['mismatches'],\n",
    "                        'Accuracy (%)': round(accuracy, 1),\n",
    "                        'Comments/Notes': \"; \".join(comments) if comments else \"OK\"\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def compare_and_export(whisper_file: pd.DataFrame, human_file: pd.DataFrame, \n",
    "                      output_path: str = \"transcription_comparison.csv\") -> Tuple[pd.DataFrame, Dict]:\n",
    "    \"\"\"Compare transcriptions and export results\"\"\"\n",
    "    # Initialize comparator\n",
    "    comparator = EnhancedTranscriptionComparator(whisper_file, human_file)\n",
    "    \n",
    "    # Generate comparison results\n",
    "    results_df = comparator.generate_comparison_results()\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    stats = {\n",
    "        'Total Segments': len(results_df),\n",
    "        'Average Accuracy': results_df['Accuracy (%)'].mean(),\n",
    "        'Average Similarity': results_df['SequenceMatcher Score'].mean(),\n",
    "        'High Quality Matches': len(results_df[results_df['Accuracy (%)'] > 80]),\n",
    "        'Low Quality Matches': len(results_df[results_df['Accuracy (%)'] < 60])\n",
    "    }\n",
    "    \n",
    "    # Export to CSV\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nComparison Summary:\")\n",
    "    print(f\"Total segments analyzed: {stats['Total Segments']}\")\n",
    "    print(f\"Average accuracy: {stats['Average Accuracy']:.1f}%\")\n",
    "    print(f\"Average similarity score: {stats['Average Similarity']:.3f}\")\n",
    "    print(f\"High quality matches (>80%): {stats['High Quality Matches']}\")\n",
    "    print(f\"Low quality matches (<60%): {stats['Low Quality Matches']}\")\n",
    "    \n",
    "    return results_df, stats\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume whisper_df and human_df are your input DataFrames\n",
    "    results_df, stats = compare_and_export(whisper_df, human_df, \"/Users/yueyan/Documents/project/wearable/transcription/12mon/002_12_transcription_comparison.csv\")\n",
    "    \n",
    "    # Display first few results\n",
    "    print(\"\\nSample comparison results:\")\n",
    "    print(results_df[['Time Range', 'Human Transcription', \n",
    "                     'Whisper Transcription', 'Accuracy (%)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109b288-71ba-4f5e-b7e0-a2df248ba215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

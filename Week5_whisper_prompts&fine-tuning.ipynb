{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8192eba-1b2c-4bb7-a202-1b8611e71d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a9f76-5476-4c85-b556-10f53bae9094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626984e-9756-450b-af23-9b33a754eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "###preprocessing + prompts \n",
    "def transcribe_audio(audio_path, speaker_hints=None):\n",
    "    \"\"\"Transcribe audio using Whisper with enhanced speaker detection\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    model = whisper.load_model(\"large-v2\", device=\"cpu\")\n",
    "    \n",
    "    # Add initial prompt to encourage speaker labeling\n",
    "    initial_prompt = \"\"\"This is a parent-infant interaction transcript. \n",
    "    Speakers include Mother, Father, and Baby. \n",
    "    Format: [Speaker] followed by speech content.\"\"\"\n",
    "    \n",
    "    print(\"Transcribing...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        word_timestamps=True,\n",
    "        verbose=True,\n",
    "        initial_prompt=initial_prompt,\n",
    "        language=\"en\",\n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    # Process segments\n",
    "    segments = []\n",
    "    if speaker_hints is None:\n",
    "        speaker_hints = [\n",
    "            \"[Mother]\", \"[Father]\", \"[Baby]\",\n",
    "            \"[Infant Vocalization]\", \"[Baby Crying]\", \"[Baby Laughing]\"\n",
    "        ]\n",
    "    \n",
    "    # Helper function for speaker detection\n",
    "    def detect_speaker(text, previous_speaker=None):\n",
    "        # Check for explicit speaker markers\n",
    "        for hint in speaker_hints:\n",
    "            if hint.lower() in text.lower():\n",
    "                return hint\n",
    "            \n",
    "        # Acoustic and content-based heuristics\n",
    "        words = text.lower().split()\n",
    "        \n",
    "        # Check for infant-specific patterns\n",
    "        baby_patterns = ['goo', 'gah', 'bah', 'mama', 'dada', 'babbling', 'crying', 'laughing']\n",
    "        if any(pattern in text.lower() for pattern in baby_patterns):\n",
    "            return '[Baby]'\n",
    "        \n",
    "        # Check for parent-specific patterns\n",
    "        parent_patterns = [\n",
    "            'good job', 'look at', 'here we go', 'that\\'s right',\n",
    "            'can you', 'let\\'s', 'sweetie', 'honey', 'baby'\n",
    "        ]\n",
    "        if any(pattern in text.lower() for pattern in parent_patterns):\n",
    "            return previous_speaker if previous_speaker in ['[Mother]', '[Father]'] else '[Mother]'\n",
    "        \n",
    "        # Context continuation\n",
    "        if previous_speaker and len(text.split()) < 5:  # Short utterances likely continue previous speaker\n",
    "            return previous_speaker\n",
    "            \n",
    "        return previous_speaker if previous_speaker else \"[Unknown]\"\n",
    "    \n",
    "    # Process segments with context\n",
    "    previous_speaker = None\n",
    "    min_segment_duration = 0.3  # Minimum duration for a valid segment\n",
    "    \n",
    "    for i, segment in enumerate(result[\"segments\"]):\n",
    "        text = segment[\"text\"].strip()\n",
    "        start = segment[\"start\"]\n",
    "        end = segment[\"end\"]\n",
    "        duration = end - start\n",
    "        \n",
    "        # Skip very short segments that might be noise\n",
    "        if duration < min_segment_duration:\n",
    "            continue\n",
    "        \n",
    "        # Enhanced speaker detection\n",
    "        detected_speaker = detect_speaker(text, previous_speaker)\n",
    "        \n",
    "        # Update previous speaker if we have a confident detection\n",
    "        if detected_speaker != \"[Unknown]\":\n",
    "            previous_speaker = detected_speaker\n",
    "        \n",
    "        # Add segment info\n",
    "        segment_info = {\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'start_time': str(timedelta(seconds=int(start))),\n",
    "            'end_time': str(timedelta(seconds=int(end))),\n",
    "            'speaker': detected_speaker,\n",
    "            'text': text,\n",
    "            'duration': duration,\n",
    "            'words_per_second': len(text.split()) / duration if duration > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Add confidence metrics\n",
    "        segment_info['confidence'] = 'high' if detected_speaker != \"[Unknown]\" else 'low'\n",
    "        \n",
    "        segments.append(segment_info)\n",
    "    \n",
    "    # Post-process segments to improve speaker consistency\n",
    "    df = pd.DataFrame(segments)\n",
    "    \n",
    "    # Smooth speaker labels using a rolling window\n",
    "    window_size = 3\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['speaker'] == \"[Unknown]\":\n",
    "            # Look at surrounding segments\n",
    "            start_idx = max(0, i - window_size)\n",
    "            end_idx = min(len(df), i + window_size + 1)\n",
    "            window = df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Count speaker occurrences in window\n",
    "            speaker_counts = window['speaker'].value_counts()\n",
    "            if len(speaker_counts) > 0 and speaker_counts.index[0] != \"[Unknown]\":\n",
    "                df.at[i, 'speaker'] = speaker_counts.index[0]\n",
    "    \n",
    "    return df, result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    speaker_hints = [\n",
    "        \"[Mother]\", \"[Father]\", \"[Baby]\",\n",
    "        \"[Infant Vocalization]\", \"[Baby Crying]\", \"[Baby Laughing]\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        df, result = transcribe_audio(\n",
    "            \"/Users/yueyan/Documents/project/wearable/media/025_04/IW_025_04_YT.wav\",\n",
    "            speaker_hints=speaker_hints\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        df.to_csv(\"/Users/yueyan/Documents/project/wearable/transcription/025_04_whisper_results_with_speaker.csv\", index=False)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nTranscription Statistics:\")\n",
    "        print(f\"Total segments: {len(df)}\")\n",
    "        print(\"\\nSpeaker distribution:\")\n",
    "        print(df['speaker'].value_counts())\n",
    "        \n",
    "        print(\"\\nFirst few transcriptions:\")\n",
    "        print(df[['start_time', 'end_time', 'speaker', 'text']].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af5f06-30ea-410d-9b67-e88868ae85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b36d3-49dd-4c25-ab40-78e693ae0ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fc837-c3ec-457c-98ae-a91d0df4ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b1dd5-8f45-4595-a038-40e0ad019124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8192eba-1b2c-4bb7-a202-1b8611e71d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import librosa\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a9f76-5476-4c85-b556-10f53bae9094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626984e-9756-450b-af23-9b33a754eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "\n",
    "###preprocessing + prompts \n",
    "def transcribe_audio(audio_path, speaker_hints=None):\n",
    "    \"\"\"Transcribe audio using Whisper with enhanced speaker detection\"\"\"\n",
    "    print(\"Loading model...\")\n",
    "    model = whisper.load_model(\"large-v2\", device=\"cpu\")\n",
    "    \n",
    "    # Add initial prompt to encourage speaker labeling\n",
    "    initial_prompt = \"\"\"This is a parent-infant interaction transcript. \n",
    "    Speakers include Mother, Father, and Baby. \n",
    "    Format: [Speaker] followed by speech content.\"\"\"\n",
    "    \n",
    "    print(\"Transcribing...\")\n",
    "    result = model.transcribe(\n",
    "        audio_path,\n",
    "        word_timestamps=True,\n",
    "        verbose=True,\n",
    "        initial_prompt=initial_prompt,\n",
    "        language=\"en\",\n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    # Process segments\n",
    "    segments = []\n",
    "    if speaker_hints is None:\n",
    "        speaker_hints = [\n",
    "            \"[Mother]\", \"[Father]\", \"[Baby]\",\n",
    "            \"[Infant Vocalization]\", \"[Baby Crying]\", \"[Baby Laughing]\"\n",
    "        ]\n",
    "    \n",
    "    # Helper function for speaker detection\n",
    "    def detect_speaker(text, previous_speaker=None):\n",
    "        # Check for explicit speaker markers\n",
    "        for hint in speaker_hints:\n",
    "            if hint.lower() in text.lower():\n",
    "                return hint\n",
    "            \n",
    "        # Acoustic and content-based heuristics\n",
    "        words = text.lower().split()\n",
    "        \n",
    "        # Check for infant-specific patterns\n",
    "        baby_patterns = ['goo', 'gah', 'bah', 'mama', 'dada', 'babbling', 'crying', 'laughing']\n",
    "        if any(pattern in text.lower() for pattern in baby_patterns):\n",
    "            return '[Baby]'\n",
    "        \n",
    "        # Check for parent-specific patterns\n",
    "        parent_patterns = [\n",
    "            'good job', 'look at', 'here we go', 'that\\'s right',\n",
    "            'can you', 'let\\'s', 'sweetie', 'honey', 'baby'\n",
    "        ]\n",
    "        if any(pattern in text.lower() for pattern in parent_patterns):\n",
    "            return previous_speaker if previous_speaker in ['[Mother]', '[Father]'] else '[Mother]'\n",
    "        \n",
    "        # Context continuation\n",
    "        if previous_speaker and len(text.split()) < 5:  # Short utterances likely continue previous speaker\n",
    "            return previous_speaker\n",
    "            \n",
    "        return previous_speaker if previous_speaker else \"[Unknown]\"\n",
    "    \n",
    "    # Process segments with context\n",
    "    previous_speaker = None\n",
    "    min_segment_duration = 0.3  # Minimum duration for a valid segment\n",
    "    \n",
    "    for i, segment in enumerate(result[\"segments\"]):\n",
    "        text = segment[\"text\"].strip()\n",
    "        start = segment[\"start\"]\n",
    "        end = segment[\"end\"]\n",
    "        duration = end - start\n",
    "        \n",
    "        # Skip very short segments that might be noise\n",
    "        if duration < min_segment_duration:\n",
    "            continue\n",
    "        \n",
    "        # Enhanced speaker detection\n",
    "        detected_speaker = detect_speaker(text, previous_speaker)\n",
    "        \n",
    "        # Update previous speaker if we have a confident detection\n",
    "        if detected_speaker != \"[Unknown]\":\n",
    "            previous_speaker = detected_speaker\n",
    "        \n",
    "        # Add segment info\n",
    "        segment_info = {\n",
    "            'start': start,\n",
    "            'end': end,\n",
    "            'start_time': str(timedelta(seconds=int(start))),\n",
    "            'end_time': str(timedelta(seconds=int(end))),\n",
    "            'speaker': detected_speaker,\n",
    "            'text': text,\n",
    "            'duration': duration,\n",
    "            'words_per_second': len(text.split()) / duration if duration > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Add confidence metrics\n",
    "        segment_info['confidence'] = 'high' if detected_speaker != \"[Unknown]\" else 'low'\n",
    "        \n",
    "        segments.append(segment_info)\n",
    "    \n",
    "    # Post-process segments to improve speaker consistency\n",
    "    df = pd.DataFrame(segments)\n",
    "    \n",
    "    # Smooth speaker labels using a rolling window\n",
    "    window_size = 3\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['speaker'] == \"[Unknown]\":\n",
    "            # Look at surrounding segments\n",
    "            start_idx = max(0, i - window_size)\n",
    "            end_idx = min(len(df), i + window_size + 1)\n",
    "            window = df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Count speaker occurrences in window\n",
    "            speaker_counts = window['speaker'].value_counts()\n",
    "            if len(speaker_counts) > 0 and speaker_counts.index[0] != \"[Unknown]\":\n",
    "                df.at[i, 'speaker'] = speaker_counts.index[0]\n",
    "    \n",
    "    return df, result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    speaker_hints = [\n",
    "        \"[Mother]\", \"[Father]\", \"[Baby]\",\n",
    "        \"[Infant Vocalization]\", \"[Baby Crying]\", \"[Baby Laughing]\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        df, result = transcribe_audio(\n",
    "            \"/Users/yueyan/Documents/project/wearable/media/025_04/IW_025_04_YT.wav\",\n",
    "            speaker_hints=speaker_hints\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        df.to_csv(\"/Users/yueyan/Documents/project/wearable/transcription/025_04_whisper_results_with_speaker.csv\", index=False)\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nTranscription Statistics:\")\n",
    "        print(f\"Total segments: {len(df)}\")\n",
    "        print(\"\\nSpeaker distribution:\")\n",
    "        print(df['speaker'].value_counts())\n",
    "        \n",
    "        print(\"\\nFirst few transcriptions:\")\n",
    "        print(df[['start_time', 'end_time', 'speaker', 'text']].head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af5f06-30ea-410d-9b67-e88868ae85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "####reliability checks \n",
    "class TranscriptionComparator:\n",
    "    def __init__(self, whisper_df: pd.DataFrame, human_df: pd.DataFrame):\n",
    "        \"\"\"Initialize with enhanced text cleaning\"\"\"\n",
    "        self.whisper_data = whisper_df.copy()\n",
    "        self.human_data = human_df.copy()\n",
    "        \n",
    "        # Pre-clean the data\n",
    "        #Removes rows with missing text\n",
    "        #fix space after \"end\" (could be deleted)\n",
    "        self.human_data = self.human_data[self.human_data['text'].notna()]\n",
    "        self.human_data = self.human_data.rename(columns={'end ': 'end'})\n",
    "        \n",
    "        # Convert times to numeric\n",
    "        # Ensures time values are numeric for calculations\n",
    "        self.human_data['start'] = pd.to_numeric(self.human_data['start'])\n",
    "        self.human_data['end'] = pd.to_numeric(self.human_data['end'])\n",
    "        \n",
    "        # Clean text thoroughly\n",
    "        # while preserving originals\n",
    "        self.whisper_data['clean_text'] = self.whisper_data['text'].apply(self.clean_text)\n",
    "        self.human_data['clean_text'] = self.human_data['text'].apply(self.clean_text)\n",
    "        \n",
    "        # Store original text for reference\n",
    "        self.whisper_data['original_text'] = self.whisper_data['text']\n",
    "        self.human_data['original_text'] = self.human_data['text']\n",
    "        \n",
    "        # Find overlap range\n",
    "        # Determines the time range where both transcriptions overlap\n",
    "        # Uses max of starts and min of ends to find common time period\n",
    "        self.overlap_start = max(\n",
    "            self.whisper_data['start'].min(),\n",
    "            self.human_data['start'].min()\n",
    "        )\n",
    "        self.overlap_end = min(\n",
    "            self.whisper_data['end'].max(),\n",
    "            self.human_data['end'].max()\n",
    "        )\n",
    "        \n",
    "        print(f\"Data loaded and cleaned. Time range: {self.overlap_start:.2f}s - {self.overlap_end:.2f}s\")\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        text cleaning function\n",
    "        - Converts to lowercase\n",
    "        - Removes punctuation\n",
    "        - Removes extra whitespace\n",
    "        - Standardizes common transcription artifacts\n",
    "        \"\"\"\n",
    "\n",
    "        # Handles missing/NaN values by returning empty string\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "            \n",
    "        # Convert to string and lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Standardize whitespace\n",
    "        # Normalizes spacing (removes extra spaces)\n",
    "        text = \" \".join(text.split())\n",
    "        \n",
    "        # Standardize common transcription variations\n",
    "        # could be adjusted \n",
    "        # Maps different spellings/variations to standard forms\n",
    "        replacements = {\n",
    "            'uhm': 'um',\n",
    "            'uhh': 'uh',\n",
    "            'hmm': 'hm',\n",
    "            'mhm': 'mm',\n",
    "            'yeah': 'yes',\n",
    "            'yah': 'yes',\n",
    "            'nah': 'no'\n",
    "        }\n",
    "        \n",
    "        for old, new in replacements.items():\n",
    "            text = re.sub(r'\\b' + old + r'\\b', new, text)\n",
    "            \n",
    "        return text\n",
    "        \n",
    "    def show_text_cleaning_examples(self, n_examples: int = 5):\n",
    "        \"\"\"Show examples of text cleaning\"\"\"\n",
    "        print(\"\\nText Cleaning Examples:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Whisper examples\n",
    "        print(\"\\nWhisper Transcription Examples:\")\n",
    "        samples = self.whisper_data.sample(n=n_examples)\n",
    "        for _, row in samples.iterrows():\n",
    "            print(f\"Original: {row['original_text']}\")\n",
    "            print(f\"Cleaned : {row['clean_text']}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "        # Human examples\n",
    "        print(\"\\nHuman Transcription Examples:\")\n",
    "        samples = self.human_data.sample(n=n_examples)\n",
    "        for _, row in samples.iterrows():\n",
    "            print(f\"Original: {row['original_text']}\")\n",
    "            print(f\"Cleaned : {row['clean_text']}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "    # Main comparison function\n",
    "    # time_tolerance: allows segments to be slightly offset (0.5 seconds)\n",
    "    # similarity_threshold: minimum text similarity to consider a match (0.3 or 30%)\n",
    "    def find_overlapping_segments(self, time_tolerance: float = 0.5, \n",
    "                                similarity_threshold: float = 0.3):\n",
    "        \"\"\"Find overlapping segments with cleaned text comparison\"\"\"\n",
    "        overlapping = []\n",
    "        \n",
    "        # Filter relevant segments to only those within overlap period\n",
    "        # Reduces processing by excluding non-overlapping parts\n",
    "        human_segments = self.human_data[\n",
    "            (self.human_data['start'] >= self.overlap_start) &\n",
    "            (self.human_data['end'] <= self.overlap_end)\n",
    "        ]\n",
    "\n",
    "        \n",
    "        whisper_segments = self.whisper_data[\n",
    "            (self.whisper_data['start'] >= self.overlap_start) &\n",
    "            (self.whisper_data['end'] <= self.overlap_end)\n",
    "        ]\n",
    "        \n",
    "        print(f\"Processing {len(human_segments)} segments...\")\n",
    "\n",
    "        # Iterates through human segments with progress bar\n",
    "        for _, human_seg in tqdm(human_segments.iterrows()):\n",
    "            # Find potential matches\n",
    "            potential_matches = whisper_segments[\n",
    "                (whisper_segments['start'] >= human_seg['start'] - time_tolerance) &\n",
    "                (whisper_segments['start'] <= human_seg['end'] + time_tolerance)\n",
    "            ]\n",
    "            \n",
    "            for _, whisper_seg in potential_matches.iterrows():\n",
    "                # Calculate similarity using cleaned text\n",
    "                # Returns ratio between 0 (completely different) and 1 (identical)\n",
    "                \"\"\"\n",
    "                Demonstrates SequenceMatcher algorithm with visualization\n",
    "    \n",
    "                Formula for ratio calculation:\n",
    "                ratio = 2.0 * M / (T1 + T2)\n",
    "                where:\n",
    "                - M = sum of length of matching blocks\n",
    "                - T1 = length of text1\n",
    "                - T2 = length of text2\n",
    "                \"\"\"\n",
    "                similarity = SequenceMatcher(\n",
    "                    None,\n",
    "                    human_seg['clean_text'],\n",
    "                    whisper_seg['clean_text']\n",
    "                ).ratio()\n",
    "                \n",
    "                if similarity > similarity_threshold:\n",
    "                    overlapping.append({\n",
    "                        'start_human': human_seg['start'],\n",
    "                        'end_human': human_seg['end'],\n",
    "                        'text_human_original': human_seg['original_text'],\n",
    "                        'text_human_cleaned': human_seg['clean_text'],\n",
    "                        'start_whisper': whisper_seg['start'],\n",
    "                        'end_whisper': whisper_seg['end'],\n",
    "                        'text_whisper_original': whisper_seg['original_text'],\n",
    "                        'text_whisper_cleaned': whisper_seg['clean_text'],\n",
    "                        'text_similarity': similarity,\n",
    "                        'time_diff': abs(human_seg['start'] - whisper_seg['start'])\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(overlapping)\n",
    "\n",
    "    def analyze_overlap(self):\n",
    "        \"\"\"Analyze overlapping segments with detailed text comparison\"\"\"\n",
    "        overlapping = self.find_overlapping_segments()\n",
    "        \n",
    "        stats = {\n",
    "            'overlap_duration': self.overlap_end - self.overlap_start,\n",
    "            'total_duration_whisper': self.whisper_data['end'].max() - self.whisper_data['start'].min(),\n",
    "            'total_duration_human': self.human_data['end'].max() - self.human_data['start'].min(),\n",
    "            'matching_segments': len(overlapping),\n",
    "            'average_similarity': overlapping['text_similarity'].mean() if len(overlapping) > 0 else 0,\n",
    "            'high_similarity_matches': len(overlapping[overlapping['text_similarity'] > 0.7])\n",
    "        }\n",
    "        \n",
    "        return overlapping, stats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b36d3-49dd-4c25-ab40-78e693ae0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load your dataframes\n",
    "    whisper_df = pd.read_csv(\"/Users/yueyan/Documents/project/wearable/transcription/025_04_whisper_results_with_speaker.csv\")\n",
    "    human_df = pd.read_csv(\"/Users/yueyan/Documents/project/wearable/transcription/025_04_human_transcription.csv\")\n",
    "    \n",
    "    # Create comparator\n",
    "    comparator = TranscriptionComparator(whisper_df, human_df)\n",
    "    \n",
    "    # Show text cleaning examples\n",
    "    comparator.show_text_cleaning_examples()\n",
    "    \n",
    "    # Analyze overlaps\n",
    "    overlapping, stats = comparator.analyze_overlap()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nResults:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    \n",
    "    print(f\"\\nProcessing time: {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save results with both original and cleaned text\n",
    "    overlapping.to_csv(\"overlap_comparison_with_text.csv\", index=False)\n",
    "\n",
    "\n",
    "# Create comparator\n",
    "comparator = TranscriptionComparator(whisper_df, human_df)\n",
    "\n",
    "# Show cleaning examples\n",
    "comparator.show_text_cleaning_examples()\n",
    "\n",
    "# Run comparison\n",
    "overlapping, stats = comparator.analyze_overlap()\n",
    "\n",
    "# Check specific examples\n",
    "print(\"\\nExample Comparisons:\")\n",
    "for _, row in overlapping.head().iterrows():\n",
    "    print(\"\\nHuman    :\", row['text_human_original'])\n",
    "    print(\"Cleaned  :\", row['text_human_cleaned'])\n",
    "    print(\"Whisper  :\", row['text_whisper_original'])\n",
    "    print(\"Cleaned  :\", row['text_whisper_cleaned'])\n",
    "    print(f\"Similarity: {row['text_similarity']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fc837-c3ec-457c-98ae-a91d0df4ac89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b1dd5-8f45-4595-a038-40e0ad019124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
